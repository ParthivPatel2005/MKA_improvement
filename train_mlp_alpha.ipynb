{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c0e179",
   "metadata": {},
   "source": [
    "# Learnable MLP Alpha Training for MKA\n",
    "\n",
    "Train and evaluate MLP-based dynamic Œ± for layer merging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad081d93",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ece401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logged in to HuggingFace\n",
      "============================================================\n",
      "MLP ALPHA EXPERIMENT - CONFIGURATION\n",
      "============================================================\n",
      "  Model: meta-llama/Meta-Llama-3-8B\n",
      "  Layers to merge: 13\n",
      "  Training steps: 500\n",
      "  Learning rate: 0.0001\n",
      "  MLP Mode: ENABLED (4 features ‚Üí hidden ‚Üí Œ±)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from huggingface_hub import login\n",
    "\n",
    "# HuggingFace Authentication\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"‚úì Logged in to HuggingFace\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"meta-llama/Meta-Llama-3-8B\"\n",
    "DATA_DIR = \"./data\"\n",
    "NUM_LAYERS = 13  # Must match your baseline evaluation\n",
    "\n",
    "# Training hyperparameters\n",
    "ALPHA_TRAINING_STEPS = 500\n",
    "ALPHA_LEARNING_RATE = 1e-4\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MLP ALPHA EXPERIMENT - CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Model: {MODEL_PATH}\")\n",
    "print(f\"  Layers to merge: {NUM_LAYERS}\")\n",
    "print(f\"  Training steps: {ALPHA_TRAINING_STEPS}\")\n",
    "print(f\"  Learning rate: {ALPHA_LEARNING_RATE}\")\n",
    "print(f\"  MLP Mode: ENABLED (4 features ‚Üí hidden ‚Üí Œ±)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e67ef",
   "metadata": {},
   "source": [
    "## 2. Download MMLU Dataset (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MMLU dataset (only need to run once)\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    print(\"üì• Downloading MMLU dataset...\")\n",
    "    # Clone the official MMLU repository\n",
    "    !git clone https://github.com/hendrycks/test.git mmlu_download\n",
    "    \n",
    "    # Move the data folder\n",
    "    !mv mmlu_download/data ./data\n",
    "    \n",
    "    # Clean up\n",
    "    !rm -rf mmlu_download\n",
    "    \n",
    "    # Verify structure\n",
    "    if os.path.exists(\"./data/dev\") and os.path.exists(\"./data/test\"):\n",
    "        print(\"‚úÖ MMLU dataset downloaded successfully!\")\n",
    "        dev_count = len([f for f in os.listdir(\"./data/dev\") if f.endswith(\"_dev.csv\")])\n",
    "        test_count = len([f for f in os.listdir(\"./data/test\") if f.endswith(\"_test.csv\")])\n",
    "        print(f\"   Dev files: {dev_count}, Test files: {test_count}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Download completed but structure looks wrong\")\n",
    "else:\n",
    "    print(\"‚úÖ Data directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536106c",
   "metadata": {},
   "source": [
    "## 3. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776bd8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data directory exists: 57 dev files, 57 test files\n"
     ]
    }
   ],
   "source": [
    "# Check data directory\n",
    "if os.path.exists(DATA_DIR):\n",
    "    dev_files = os.listdir(os.path.join(DATA_DIR, \"dev\")) if os.path.exists(os.path.join(DATA_DIR, \"dev\")) else []\n",
    "    test_files = os.listdir(os.path.join(DATA_DIR, \"test\")) if os.path.exists(os.path.join(DATA_DIR, \"test\")) else []\n",
    "    print(f\"‚úì Data directory exists: {len(dev_files)} dev files, {len(test_files)} test files\")\n",
    "else:\n",
    "    print(f\"‚úó Data directory not found: {DATA_DIR}\")\n",
    "    print(\"  Make sure MMLU data is in ./data/dev/ and ./data/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861f350",
   "metadata": {},
   "source": [
    "## 4. Train MLP-based Alpha (saves model, ~30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0018c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping baseline - using existing results for num_layer=13\n"
     ]
    }
   ],
   "source": [
    "# SKIP THIS if you already have baseline results for num_layer=13\n",
    "print(\"‚ö†Ô∏è Skipping baseline - using existing results for num_layer=13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e583f94",
   "metadata": {},
   "source": [
    "## 5. Load Fused Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce790b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:09<00:29,  9.94s/it]\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.49s/it]\n",
      "\n",
      "Processing abstract_algebra:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Processing abstract_algebra: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [25:49<00:00, 1549.49s/it]\n",
      "Processing abstract_algebra: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [25:49<00:00, 1549.54s/it]\n",
      "\n",
      "Processing anatomy:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set pad_token to eos_token: <|end_of_text|>\n",
      "Initial model configuration: LlamaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "Model metadata:\n",
      "Number of layers: 32\n",
      "Config num_hidden_layers: 32\n"
     ]
    }
   ],
   "source": [
    "# Train MLP alpha and evaluate on MMLU\n",
    "!python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 13 --data_dir \"./data\" --use_learnable_alpha --use_mlp_merge --alpha_training_steps 500 --alpha_learning_rate 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fused model with learned MLP alphas\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Path to the saved fused model\n",
    "MODEL_DIR = f\"./output/Meta-Llama-3-8B/fused_{NUM_LAYERS}_layers/iteration/merged_weights\"\n",
    "\n",
    "print(\"Loading fused model with learned MLP alphas...\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "\n",
    "# Check if model exists\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    print(f\"‚ùå Model directory not found: {MODEL_DIR}\")\n",
    "    print(\"   Make sure training has completed successfully.\")\n",
    "else:\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "        padding_side=\"left\"\n",
    "    )\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # Load the fused model\n",
    "    fused_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_DIR,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float32,\n",
    "    )\n",
    "    \n",
    "    # Disable caching\n",
    "    fused_model.config.use_cache = False\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"   Number of layers: {fused_model.config.num_hidden_layers}\")\n",
    "    print(f\"   Model dtype: {fused_model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9f8aa",
   "metadata": {},
   "source": [
    "## 6. Evaluate on MMLU (~40-90 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fe91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on MMLU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# MMLU evaluation function\n",
    "choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "def format_subject(subject):\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s\n",
    "\n",
    "def format_example(df, idx, include_answer=True):\n",
    "    prompt = df.iloc[idx, 0]\n",
    "    k = df.shape[1] - 2\n",
    "    for j in range(k):\n",
    "        prompt += \"\\n{}. {}\".format(choices[j], df.iloc[idx, j + 1])\n",
    "    prompt += \"\\nAnswer:\"\n",
    "    if include_answer:\n",
    "        prompt += \" {}\\n\\n\".format(df.iloc[idx, k + 1])\n",
    "    return prompt\n",
    "\n",
    "def gen_prompt(train_df, subject, k=-1):\n",
    "    prompt = \"The following are multiple choice questions (with answers) about {}.\\n\\n\".format(\n",
    "        format_subject(subject)\n",
    "    )\n",
    "    if k == -1:\n",
    "        k = train_df.shape[0]\n",
    "    for i in range(k):\n",
    "        prompt += format_example(train_df, i)\n",
    "    return prompt\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_subject(subject, model, tokenizer, dev_df, test_df, ntrain=5):\n",
    "    cors = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in tqdm(range(test_df.shape[0]), desc=f\"Evaluating {subject}\"):\n",
    "        prompt_end = format_example(test_df, i, include_answer=False)\n",
    "        train_prompt = gen_prompt(dev_df, subject, ntrain)\n",
    "        prompt = train_prompt + prompt_end\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "        labels = input_ids.clone()\n",
    "        labels[:, :-len(tokenizer(prompt_end).input_ids)] = -100\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, labels=labels, use_cache=False)\n",
    "        logits = outputs.logits[:, -1, :]\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1).detach().float().cpu().numpy()\n",
    "        pred = choices[np.argmax(probs[:, [tokenizer(c).input_ids[-1] for c in choices]])]\n",
    "        label = test_df.iloc[i, test_df.shape[1] - 1]\n",
    "        \n",
    "        cor = pred == label\n",
    "        cors.append(cor)\n",
    "    \n",
    "    acc = np.mean(cors)\n",
    "    avg_loss = total_loss / len(test_df)\n",
    "    ppl = np.exp(avg_loss)\n",
    "    \n",
    "    return acc, ppl\n",
    "\n",
    "# Run evaluation on all subjects\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING FUSED MODEL ON MMLU (MLP-BASED ALPHA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fused_model.eval()\n",
    "\n",
    "subjects = sorted([\n",
    "    f.split(\"_test.csv\")[0]\n",
    "    for f in os.listdir(os.path.join(DATA_DIR, \"test\"))\n",
    "    if \"_test.csv\" in f\n",
    "])\n",
    "\n",
    "all_accs = {}\n",
    "all_ppls = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    dev_df = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"dev\", subject + \"_dev.csv\"), header=None\n",
    "    )[:5]  # Use 5 examples\n",
    "    test_df = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"test\", subject + \"_test.csv\"), header=None\n",
    "    )\n",
    "    \n",
    "    acc, ppl = eval_subject(subject, fused_model, tokenizer, dev_df, test_df, ntrain=5)\n",
    "    \n",
    "    all_accs[subject] = acc\n",
    "    all_ppls[subject] = ppl\n",
    "    \n",
    "    print(f\"Average accuracy {acc:.3f} - {subject}\")\n",
    "    print(f\"Perplexity {ppl:.3f} - {subject}\")\n",
    "\n",
    "avg_acc = np.mean(list(all_accs.values()))\n",
    "avg_ppl = np.mean(list(all_ppls.values()))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MMLU EVALUATION RESULTS (MLP-BASED ALPHA)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average Accuracy:   {avg_acc:.4f}\")\n",
    "print(f\"Average Perplexity: {avg_ppl:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    \"average_accuracy\": float(avg_acc),\n",
    "    \"average_perplexity\": float(avg_ppl),\n",
    "    \"per_subject_accuracy\": {k: float(v) for k, v in all_accs.items()},\n",
    "    \"per_subject_perplexity\": {k: float(v) for k, v in all_ppls.items()},\n",
    "}\n",
    "\n",
    "results_path = f\"./output/Meta-Llama-3-8B/fused_{NUM_LAYERS}_layers/iteration/fusion_info/mmlu_results.json\"\n",
    "os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec679d",
   "metadata": {},
   "source": [
    "## 7. Visualize Top/Bottom Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top and bottom performing subjects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort subjects by accuracy\n",
    "sorted_subjects = sorted(all_accs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get top 10 and bottom 10\n",
    "top_10 = sorted_subjects[:10]\n",
    "bottom_10 = sorted_subjects[-10:]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 10 subjects\n",
    "subjects_top = [s[0] for s in top_10]\n",
    "accs_top = [s[1] for s in top_10]\n",
    "\n",
    "ax1.barh(range(len(subjects_top)), accs_top, color='green', alpha=0.7)\n",
    "ax1.set_yticks(range(len(subjects_top)))\n",
    "ax1.set_yticklabels(subjects_top, fontsize=10)\n",
    "ax1.set_xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Top 10 Subjects by Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add accuracy values on bars\n",
    "for i, acc in enumerate(accs_top):\n",
    "    ax1.text(acc + 0.01, i, f'{acc:.3f}', va='center', fontsize=10)\n",
    "\n",
    "# Bottom 10 subjects\n",
    "subjects_bottom = [s[0] for s in bottom_10]\n",
    "accs_bottom = [s[1] for s in bottom_10]\n",
    "\n",
    "ax2.barh(range(len(subjects_bottom)), accs_bottom, color='red', alpha=0.7)\n",
    "ax2.set_yticks(range(len(subjects_bottom)))\n",
    "ax2.set_yticklabels(subjects_bottom, fontsize=10)\n",
    "ax2.set_xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Bottom 10 Subjects by Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add accuracy values on bars\n",
    "for i, acc in enumerate(accs_bottom):\n",
    "    ax2.text(acc + 0.01, i, f'{acc:.3f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Overall Average Accuracy: {avg_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
