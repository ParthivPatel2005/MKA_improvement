{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c0e179",
   "metadata": {},
   "source": [
    "# MLP-Based Dynamic Alpha Training for MKA Layer Merging\n",
    "\n",
    "This notebook demonstrates training an **MLP network** to predict optimal layer merging coefficients dynamically based on input activation statistics.\n",
    "\n",
    "**Goal**: Test whether input-dependent dynamic merging outperforms static coefficients.\n",
    "\n",
    "## Method\n",
    "- Replace layer pairs with `MLPMergeableLayer` wrappers\n",
    "- Each wrapper contains a small MLP that predicts Œ± from activation statistics:\n",
    "  - Mean activation of layer 1\n",
    "  - Mean activation of layer 2\n",
    "  - Std activation of layer 1\n",
    "  - Std activation of layer 2\n",
    "- Train MLP parameters on calibration data while keeping original layers frozen\n",
    "- Alpha adapts dynamically to each input sample\n",
    "\n",
    "---\n",
    "\n",
    "## üí° **Important Notes**\n",
    "- **For actual training**: Run commands directly in terminal (see commands below)\n",
    "- **This notebook**: Use for interactive analysis and visualization of results\n",
    "- **Safety feature**: `EXECUTE_COMMANDS = False` by default to prevent accidental runs\n",
    "- **Key difference**: Uses `--use_mlp_merge` flag for dynamic alpha prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad081d93",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ece401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"meta-llama/Meta-Llama-3-8B\"\n",
    "DATA_DIR = \"./data\"\n",
    "NUM_LAYERS = 14  # Number of layer pairs to merge\n",
    "OUTPUT_DIR = \"./merged_weights_mlp\"\n",
    "\n",
    "# Training hyperparameters\n",
    "ALPHA_TRAINING_STEPS = 500\n",
    "ALPHA_LEARNING_RATE = 1e-4\n",
    "CALIBRATION_BATCH_SIZE = 4\n",
    "CALIBRATION_SAMPLES = 100\n",
    "\n",
    "# MLP-specific parameters (defined in mergeable_layer.py)\n",
    "# MLP architecture: 4 inputs -> hidden_dim (64) -> 1 output (alpha)\n",
    "\n",
    "# Safety toggle - set to True to execute commands in this notebook\n",
    "# RECOMMENDED: Run commands directly in terminal instead\n",
    "EXECUTE_COMMANDS = False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MLP ALPHA TRAINING - CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Model: {MODEL_PATH}\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Layers to merge: {NUM_LAYERS}\")\n",
    "print(f\"  Training steps: {ALPHA_TRAINING_STEPS}\")\n",
    "print(f\"  Learning rate: {ALPHA_LEARNING_RATE}\")\n",
    "print(f\"  Batch size: {CALIBRATION_BATCH_SIZE}\")\n",
    "print(f\"  Calibration samples: {CALIBRATION_SAMPLES}\")\n",
    "print(f\"  Method: MLP-based dynamic merging\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚ö†Ô∏è  EXECUTE_COMMANDS = {EXECUTE_COMMANDS}\")\n",
    "if not EXECUTE_COMMANDS:\n",
    "    print(\"    (Commands will show as dry-run only)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e67ef",
   "metadata": {},
   "source": [
    "## Step 1: Verify Required Files\n",
    "\n",
    "Before running training, ensure all required files exist:\n",
    "- Model checkpoint or HuggingFace model access\n",
    "- MMLU data files in `data/dev/` and `data/test/`\n",
    "- Similarity matrix (optional, for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data directory\n",
    "if os.path.exists(DATA_DIR):\n",
    "    dev_files = os.listdir(os.path.join(DATA_DIR, \"dev\")) if os.path.exists(os.path.join(DATA_DIR, \"dev\")) else []\n",
    "    test_files = os.listdir(os.path.join(DATA_DIR, \"test\")) if os.path.exists(os.path.join(DATA_DIR, \"test\")) else []\n",
    "    print(f\"‚úì Data directory exists\")\n",
    "    print(f\"  Dev files: {len(dev_files)}\")\n",
    "    print(f\"  Test files: {len(test_files)}\")\n",
    "else:\n",
    "    print(f\"‚úó Data directory not found: {DATA_DIR}\")\n",
    "\n",
    "# Check similarity matrix (optional)\n",
    "similarity_matrix_path = \"similarity_matrix.pkl\"\n",
    "if os.path.exists(similarity_matrix_path):\n",
    "    print(f\"‚úì Similarity matrix found: {similarity_matrix_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Similarity matrix not found (optional): {similarity_matrix_path}\")\n",
    "\n",
    "# Check output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"‚úì Output directory ready: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861f350",
   "metadata": {},
   "source": [
    "## Step 2: Train MLP Alpha Predictor\n",
    "\n",
    "This command will:\n",
    "1. Load the Llama-3-8B model\n",
    "2. Replace selected layer pairs with `MLPMergeableLayer` wrappers\n",
    "3. Train MLP networks to predict Œ± from activation statistics\n",
    "4. Note: Unlike scalar Œ±, MLP predictions are dynamic (different per input)\n",
    "5. Fuse layers using average Œ±=0.5 and save the merged model\n",
    "\n",
    "**Key Difference**: The `--use_mlp_merge` flag enables MLP-based merging.\n",
    "\n",
    "### üöÄ **Recommended: Run in Terminal**\n",
    "Copy and run this command directly in PowerShell:\n",
    "```powershell\n",
    "python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 14 --data_dir \"./data\" --use_learnable_alpha --use_mlp_merge --alpha_training_steps 500 --alpha_learning_rate 1e-4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to execute MLP training directly\n",
    "# !python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 14 --data_dir \"./data\" --use_learnable_alpha --use_mlp_merge --alpha_training_steps 500 --alpha_learning_rate 1e-4\n",
    "\n",
    "print(\"üëÜ Uncomment the line above and run this cell to train MLP alpha\")\n",
    "print(\"   OR use the subprocess approach in the next cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e583f94",
   "metadata": {},
   "source": [
    "## Alternative: Run Command Directly in Notebook\n",
    "\n",
    "You can also run the command directly in a notebook cell using `!`:\n",
    "- The `!` prefix executes shell commands from within the notebook\n",
    "- This is simpler than the `subprocess` approach below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce790b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the command\n",
    "cmd = [\n",
    "    \"python\", \"pipeline.py\",\n",
    "    \"--model_path\", MODEL_PATH,\n",
    "    \"--num_layer\", str(NUM_LAYERS),\n",
    "    \"--data_dir\", DATA_DIR,\n",
    "    \"--use_learnable_alpha\",\n",
    "    \"--use_mlp_merge\",  # This flag switches to MLP mode\n",
    "    \"--alpha_training_steps\", str(ALPHA_TRAINING_STEPS),\n",
    "    \"--alpha_learning_rate\", str(ALPHA_LEARNING_RATE),\n",
    "    \"--calibration_batch_size\", str(CALIBRATION_BATCH_SIZE),\n",
    "    \"--calibration_samples\", str(CALIBRATION_SAMPLES),\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MLP TRAINING COMMAND\")\n",
    "print(\"=\" * 60)\n",
    "print(\" \".join(cmd))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if EXECUTE_COMMANDS:\n",
    "    print(\"\\nüöÄ Executing MLP training...\\n\")\n",
    "    result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n‚úÖ MLP training completed successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training failed with exit code {result.returncode}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  EXECUTE_COMMANDS is False\")\n",
    "    print(\"   To run: Set EXECUTE_COMMANDS = True in configuration cell\")\n",
    "    print(\"   OR better: Copy the command above and run in terminal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4a1cd",
   "metadata": {},
   "source": [
    "## Step 3: Understanding MLP-Based Merging\n",
    "\n",
    "Unlike scalar Œ± which is fixed per layer pair, MLP-based Œ± is:\n",
    "- **Dynamic**: Varies for each input sample\n",
    "- **Context-aware**: Depends on activation statistics\n",
    "- **Learned**: MLP weights are optimized via gradient descent\n",
    "\n",
    "The learned alphas file will contain -1.0 values to indicate MLP layers (since Œ± varies per input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1df985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "learned_alphas_path = os.path.join(OUTPUT_DIR, \"learned_alphas.json\")\n",
    "\n",
    "if os.path.exists(learned_alphas_path):\n",
    "    with open(learned_alphas_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    learned_alphas = data.get('learned_alphas', [])\n",
    "    similarity_scores = data.get('similarity_scores', [])\n",
    "    \n",
    "    print(f\"Number of layer pairs: {len(learned_alphas)}\")\n",
    "    print(f\"\\nAlpha values (should be -1.0 for MLP layers):\")\n",
    "    print(learned_alphas[:10])  # Show first 10\n",
    "    \n",
    "    mlp_count = sum(1 for a in learned_alphas if a == -1.0)\n",
    "    print(f\"\\nMLP layers: {mlp_count} / {len(learned_alphas)}\")\n",
    "    \n",
    "    if mlp_count == len(learned_alphas):\n",
    "        print(\"‚úì All layers are MLP-based (as expected)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some layers are not MLP-based (unexpected)\")\n",
    "    \n",
    "    print(\"\\nNote: -1.0 indicates MLP-based layer where Œ± is predicted dynamically.\")\n",
    "    print(\"To analyze actual Œ± distributions, you need to:\")\n",
    "    print(\"1. Run inference on test data\")\n",
    "    print(\"2. Collect Œ± predictions for each sample\")\n",
    "    print(\"3. Analyze the distribution of predictions\")\n",
    "else:\n",
    "    print(f\"‚úó Learned alphas file not found: {learned_alphas_path}\")\n",
    "    print(\"Run the training step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2439e62",
   "metadata": {},
   "source": [
    "## Step 4: Analyze MLP Predictions (Advanced)\n",
    "\n",
    "To understand how the MLP behaves, we can load the model and examine Œ± predictions on sample inputs.\n",
    "\n",
    "**Note**: This requires loading the trained model, which is more advanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8350764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To analyze MLP predictions in detail:\")\n",
    "print(\"1. Load the model with trained MLPMergeableLayer wrappers\")\n",
    "print(\"2. Run inference on a batch of inputs\")\n",
    "print(\"3. Extract Œ± predictions from each layer's forward pass\")\n",
    "print(\"4. Analyze Œ± distribution across samples and layers\")\n",
    "print(\"\\nThis requires custom inference code and is beyond the scope of this notebook.\")\n",
    "print(\"\\nFor comparison with other methods, use evaluate_methods.py:\")\n",
    "eval_cmd = f\"python evaluate_methods.py --model_path {MODEL_PATH} --data_dir {DATA_DIR} --output_dir ./experiments --include_mlp\"\n",
    "print(eval_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76844eb",
   "metadata": {},
   "source": [
    "## Step 5: Compare with Scalar Alpha Method\n",
    "\n",
    "Run comprehensive evaluation to compare:\n",
    "1. **MKA (similarity-based)**: Original paper's heuristic\n",
    "2. **Fixed Œ±=0.5**: Uniform merging\n",
    "3. **Fixed Œ±=0.7**: Higher weight on first layer\n",
    "4. **Learned scalar Œ±**: Trainable static coefficients\n",
    "5. **Learned MLP Œ±**: Dynamic input-dependent coefficients\n",
    "\n",
    "### üéØ **Comprehensive Evaluation**\n",
    "Run this command in terminal:\n",
    "```powershell\n",
    "python evaluate_methods.py --model_path \"meta-llama/Meta-Llama-3-8B\" --data_dir \"./data\" --similarity_matrix \"similarity_matrix.pkl\" --output_dir \"./experiments\" --include_mlp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive evaluation command\n",
    "eval_cmd = [\n",
    "    \"python\", \"evaluate_methods.py\",\n",
    "    \"--model_path\", MODEL_PATH,\n",
    "    \"--data_dir\", DATA_DIR,\n",
    "    \"--similarity_matrix\", \"similarity_matrix.pkl\",\n",
    "    \"--output_dir\", \"./experiments\",\n",
    "    \"--include_mlp\",  # Include MLP-based method in comparison\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FULL EVALUATION COMMAND (ALL 5 METHODS)\")\n",
    "print(\"=\" * 60)\n",
    "print(\" \".join(eval_cmd))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if EXECUTE_COMMANDS:\n",
    "    print(\"\\nüöÄ Executing comprehensive evaluation...\\n\")\n",
    "    print(\"‚ö†Ô∏è This will take significant time (trains and evaluates 5 methods)\\n\")\n",
    "    result = subprocess.run(eval_cmd, capture_output=False, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n‚úÖ Evaluation completed successfully!\")\n",
    "        print(\"Results saved in ./experiments/\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Evaluation failed with exit code {result.returncode}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  EXECUTE_COMMANDS is False\")\n",
    "    print(\"   Copy the command above and run in terminal for full evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c112cec",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results\n",
    "\n",
    "After running evaluation, visualize the comparison between all methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = \"./experiments\"\n",
    "methods = [\"mka_similarity\", \"fixed_05\", \"fixed_07\", \"learned\", \"learned_mlp\"]\n",
    "method_names = [\n",
    "    \"MKA (Similarity)\",\n",
    "    \"Fixed Œ±=0.5\",\n",
    "    \"Fixed Œ±=0.7\",\n",
    "    \"Learned Scalar Œ±\",\n",
    "    \"Learned MLP Œ±\"\n",
    "]\n",
    "\n",
    "accuracies = []\n",
    "found_methods = []\n",
    "\n",
    "for method, name in zip(methods, method_names):\n",
    "    result_file = os.path.join(results_dir, method, \"results.json\")\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            avg_acc = data.get('average_accuracy', 0)\n",
    "            accuracies.append(avg_acc * 100)  # Convert to percentage\n",
    "            found_methods.append(name)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Results not found for {name}\")\n",
    "\n",
    "if accuracies:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    bars = plt.bar(found_methods, accuracies, color=colors[:len(found_methods)])\n",
    "    \n",
    "    plt.xlabel('Method', fontsize=12)\n",
    "    plt.ylabel('Average Accuracy (%)', fontsize=12)\n",
    "    plt.title('MMLU Accuracy Comparison: All Merging Methods', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Results Summary:\")\n",
    "    for name, acc in zip(found_methods, accuracies):\n",
    "        print(f\"  {name}: {acc:.2f}%\")\n",
    "else:\n",
    "    print(\"No results found. Run the evaluation step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4bae3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ‚úÖ Training MLP networks to predict Œ± dynamically\n",
    "2. ‚úÖ Understanding input-dependent merging behavior\n",
    "3. ‚úÖ Comparing with scalar Œ± and other baseline methods\n",
    "\n",
    "**Key Questions to Answer:**\n",
    "- Does dynamic Œ± (MLP) outperform static Œ± (scalar)?\n",
    "- How much does Œ± vary across different inputs?\n",
    "- What activation patterns lead to high/low Œ± values?\n",
    "\n",
    "**Research Hypotheses:**\n",
    "- **H1**: MLP-based merging adapts to input complexity ‚Üí better accuracy\n",
    "- **H2**: Different tasks/subjects require different merging strategies\n",
    "- **H3**: Dynamic Œ± provides more flexibility than similarity heuristic\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare with scalar alpha results (see `train_scalar_alpha.ipynb`)\n",
    "- Analyze per-subject accuracy differences\n",
    "- Investigate Œ± prediction patterns for different input types\n",
    "- Experiment with different MLP architectures (hidden size, depth)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **Quick Reference: All Commands**\n",
    "\n",
    "### Scalar Alpha Training (See Other Notebook):\n",
    "```powershell\n",
    "python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 14 --data_dir \"./data\" --use_learnable_alpha --alpha_training_steps 500 --alpha_learning_rate 1e-4\n",
    "```\n",
    "\n",
    "### MLP Alpha Training (This Notebook):\n",
    "```powershell\n",
    "python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 14 --data_dir \"./data\" --use_learnable_alpha --use_mlp_merge --alpha_training_steps 500 --alpha_learning_rate 1e-4\n",
    "```\n",
    "\n",
    "### Full Evaluation (Compare All 5 Methods):\n",
    "```powershell\n",
    "python evaluate_methods.py --model_path \"meta-llama/Meta-Llama-3-8B\" --data_dir \"./data\" --similarity_matrix \"similarity_matrix.pkl\" --output_dir \"./experiments\" --include_mlp\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Key Differences from Scalar Alpha**\n",
    "\n",
    "| Aspect | Scalar Alpha | MLP Alpha (This) |\n",
    "|--------|--------------|------------------|\n",
    "| **Flag** | `--use_learnable_alpha` | `--use_learnable_alpha --use_mlp_merge` |\n",
    "| **Layer Type** | `MergeableLayer` | `MLPMergeableLayer` |\n",
    "| **Alpha Type** | Static (1 value) | Dynamic (varies per input) |\n",
    "| **Trainable Params** | 1 scalar | ~4K MLP parameters |\n",
    "| **Learned Output** | Œ± ‚àà [0, 1] | -1.0 (indicator) |\n",
    "| **Fusion** | Use learned Œ± | Use fixed 0.5 |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
