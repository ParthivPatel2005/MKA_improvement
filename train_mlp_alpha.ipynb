{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c0e179",
   "metadata": {},
   "source": [
    "# Learnable MLP Alpha Training for MKA Layer Merging\n",
    "\n",
    "This notebook compares **baseline MKA** (similarity-based) vs **MLP-based dynamic alpha** approach.\n",
    "\n",
    "## Workflow:\n",
    "1. **Run Baseline**: Original MKA with similarity-based merging (num_layer=13)\n",
    "2. **Train MLP**: Learn MLP network to predict α from activation statistics\n",
    "3. **Evaluate**: Test both on MMLU and compare accuracy\n",
    "\n",
    "## Goal:\n",
    "Test whether an MLP that predicts α dynamically improves over static similarity-based merging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad081d93",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ece401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from huggingface_hub import login\n",
    "\n",
    "# HuggingFace Authentication\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"✓ Logged in to HuggingFace\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"meta-llama/Meta-Llama-3-8B\"\n",
    "DATA_DIR = \"./data\"\n",
    "NUM_LAYERS = 13  # Must match your baseline evaluation\n",
    "\n",
    "# Training hyperparameters\n",
    "ALPHA_TRAINING_STEPS = 500\n",
    "ALPHA_LEARNING_RATE = 1e-4\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MLP ALPHA EXPERIMENT - CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Model: {MODEL_PATH}\")\n",
    "print(f\"  Layers to merge: {NUM_LAYERS}\")\n",
    "print(f\"  Training steps: {ALPHA_TRAINING_STEPS}\")\n",
    "print(f\"  Learning rate: {ALPHA_LEARNING_RATE}\")\n",
    "print(f\"  MLP Mode: ENABLED (4 features → hidden → α)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e67ef",
   "metadata": {},
   "source": [
    "## Step 1: Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data directory\n",
    "if os.path.exists(DATA_DIR):\n",
    "    dev_files = os.listdir(os.path.join(DATA_DIR, \"dev\")) if os.path.exists(os.path.join(DATA_DIR, \"dev\")) else []\n",
    "    test_files = os.listdir(os.path.join(DATA_DIR, \"test\")) if os.path.exists(os.path.join(DATA_DIR, \"test\")) else []\n",
    "    print(f\"✓ Data directory exists: {len(dev_files)} dev files, {len(test_files)} test files\")\n",
    "else:\n",
    "    print(f\"✗ Data directory not found: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861f350",
   "metadata": {},
   "source": [
    "## Step 2A: Run Baseline (Original MKA - No Alpha Training)\n",
    "\n",
    "**Note:** You mentioned you already have baseline results for num_layer=13, so you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP THIS if you already have baseline results for num_layer=13\n",
    "print(\"⚠️ Skipping baseline - using existing results for num_layer=13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e583f94",
   "metadata": {},
   "source": [
    "## Step 2B: Train MLP-based Alpha\n",
    "\n",
    "Train MLP network to predict α dynamically, then evaluate on MMLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce790b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP alpha and evaluate on MMLU\n",
    "!python pipeline.py --model_path \"meta-llama/Meta-Llama-3-8B\" --num_layer 13 --data_dir \"./data\" --use_learnable_alpha --use_mlp_merge --alpha_training_steps 500 --alpha_learning_rate 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4bae3",
   "metadata": {},
   "source": [
    "## Step 3: Analyze MLP Predictions\n",
    "\n",
    "Analyze how the MLP predicts α values based on activation statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09796239",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook compared:\n",
    "1. **Baseline MKA** (similarity-based heuristic S_lm)\n",
    "2. **MLP-based Dynamic α** (predicted from activation statistics)\n",
    "\n",
    "**Key Findings:**\n",
    "- MLP learns to predict α based on 4 activation features (mean, std, max, norm)\n",
    "- Check if dynamic prediction improves over static similarity scores\n",
    "- Compare MMLU accuracy between baseline and MLP approach\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare with scalar alpha (see `train_scalar_alpha.ipynb`)\n",
    "- Run full comparison with `evaluate_methods.py --include_mlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with your actual baseline accuracy for num_layer=13\n",
    "baseline_accuracy = 0.0  # <-- UPDATE THIS WITH YOUR BASELINE RESULT\n",
    "\n",
    "# Load MLP results\n",
    "results_path = \"./output/Meta-Llama-3-8B/fused_13_layers/iteration/fusion_info/mmlu_results.json\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MMLU ACCURACY COMPARISON (num_layer=13)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    try:\n",
    "        with open(results_path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            mlp_accuracy = results.get('average_accuracy', 0.0)\n",
    "        \n",
    "        print(f\"Baseline (Similarity-based):  {baseline_accuracy:.4f}\")\n",
    "        print(f\"MLP-based Dynamic α:          {mlp_accuracy:.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        improvement = mlp_accuracy - baseline_accuracy\n",
    "        improvement_pct = (improvement / baseline_accuracy * 100) if baseline_accuracy > 0 else 0\n",
    "        \n",
    "        print(f\"Improvement: {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        methods = ['Baseline\\n(Similarity)', 'MLP-based\\nDynamic α']\n",
    "        accuracies = [baseline_accuracy, mlp_accuracy]\n",
    "        colors = ['#3498db', '#9b59b6']\n",
    "        \n",
    "        bars = ax1.bar(methods, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "        ax1.set_ylabel('MMLU Accuracy', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('Baseline vs MLP Alpha', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylim([min(accuracies) * 0.95 if min(accuracies) > 0 else 0, max(accuracies) * 1.05])\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.4f}',\n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        ax2.bar(['Improvement'], [improvement], color='green' if improvement > 0 else 'red', \n",
    "               alpha=0.8, edgecolor='black', linewidth=2)\n",
    "        ax2.set_ylabel('Accuracy Difference', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Performance Gain', fontsize=14, fontweight='bold')\n",
    "        ax2.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "        ax2.text(0, improvement, f'{improvement:+.4f}\\n({improvement_pct:+.2f}%)', \n",
    "                ha='center', va='bottom' if improvement > 0 else 'top', \n",
    "                fontsize=12, fontweight='bold')\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        if 'per_subject' in results:\n",
    "            print(\"\\nTop 5 subjects by accuracy:\")\n",
    "            subject_accs = [(k, v) for k, v in results['per_subject'].items()]\n",
    "            subject_accs.sort(key=lambda x: x[1], reverse=True)\n",
    "            for subject, acc in subject_accs[:5]:\n",
    "                print(f\"  {subject:40s}: {acc:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading results: {e}\")\n",
    "else:\n",
    "    print(f\"✗ Results not found: {results_path}\")\n",
    "    print(\"  Training must complete first.\")\n",
    "    \n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4369a4c",
   "metadata": {},
   "source": [
    "## Step 4: Compare MMLU Accuracy - Baseline vs MLP Alpha\n",
    "\n",
    "**Important:** Update `baseline_accuracy` with your actual baseline result for num_layer=13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b289f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MLP alpha predictions (if saved)\n",
    "mlp_alphas_path = \"./output/Meta-Llama-3-8B/fused_13_layers/iteration/merged_weights/mlp_alpha_predictions.json\"\n",
    "learned_alphas_path = \"./output/Meta-Llama-3-8B/fused_13_layers/iteration/merged_weights/learned_alphas.json\"\n",
    "\n",
    "if os.path.exists(learned_alphas_path):\n",
    "    with open(learned_alphas_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    learned_alphas = data.get('learned_alphas', [])\n",
    "    similarity_scores = data.get('similarity_scores', [])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"MLP ALPHA PREDICTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Number of layers: {len(learned_alphas)}\")\n",
    "    print(f\"  Mean α: {np.mean(learned_alphas):.4f}\")\n",
    "    print(f\"  Std α:  {np.std(learned_alphas):.4f}\")\n",
    "    print(f\"  Min α:  {np.min(learned_alphas):.4f}\")\n",
    "    print(f\"  Max α:  {np.max(learned_alphas):.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(learned_alphas, bins=15, edgecolor='black', alpha=0.7, color='purple')\n",
    "    plt.axvline(np.mean(learned_alphas), color='r', linestyle='--', label=f'Mean: {np.mean(learned_alphas):.3f}')\n",
    "    plt.xlabel('MLP Predicted α')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of MLP α')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(len(learned_alphas)), learned_alphas, marker='o', linestyle='-', color='darkblue')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('MLP Predicted α')\n",
    "    plt.title('MLP α Across Layers')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    if similarity_scores and len(similarity_scores) == len(learned_alphas):\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.scatter(similarity_scores, learned_alphas, alpha=0.6, s=100, color='orange')\n",
    "        plt.xlabel('Similarity Score (S_lm)')\n",
    "        plt.ylabel('MLP Predicted α')\n",
    "        plt.title('MLP α vs Similarity')\n",
    "        corr = np.corrcoef(similarity_scores, learned_alphas)[0, 1]\n",
    "        plt.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=plt.gca().transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ MLP analysis complete!\")\n",
    "else:\n",
    "    print(f\"✗ MLP predictions not found: {learned_alphas_path}\")\n",
    "    print(\"  Training must complete first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
